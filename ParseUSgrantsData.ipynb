{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Environment: Python 3.7.3 and Jupyter notebook\n",
    "\n",
    "Libraries used: \n",
    "\n",
    "* pandas (for dataframe, included in Anaconda Python 3.7) \n",
    "* re (for regular expression, included in Anaconda Python 3.7) \n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project involved extraction of specified data from a semi-structured xml file containing US patent data records and to export it into a specified format as a csv and a json file. \n",
    "\n",
    "Following steps were taken in order to complete this project. \n",
    "\n",
    "1. Analysis of sample input and sample output files to identify the relationship between the structure, content and format of input file and output files. \n",
    "\n",
    "2. Identification of consistent patterns to assist in use of regular expressions to select and extract required data.\n",
    "\n",
    "3. Transformation of extracted data into required format and writing it to files. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "#### Analysis of sample input and output files\n",
    "\n",
    "Following strategies were employed in searching for the location of required data in the sample input file:\n",
    "* searching for field title or part of. \n",
    "* searching for field content or part of. \n",
    "* number of occurances of same or similar information in the record\n",
    "* occurances of false matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grant_id,patent_title,kind,number_of_claims,inventors,citations_applicant_count,citations_examiner_count,claims_text,abstract\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reading sample output\n",
    "sample_output = open('sample_output.csv','r').readlines()\n",
    "\n",
    "#first line contains headers of all the columns that need to be included.\n",
    "print(sample_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries \n",
    "\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Parse XML File\n",
    "\n",
    "Entire text file is opened and read into raw_data. \n",
    "\n",
    "The information that we need from each record is within tags `<us-patent-grant...>` and `</us-patent-grant>`. \n",
    "All records are extracted from raw_data using the findall function and stored as a list of strings in records. \n",
    "(.*?) pattern captures all content between the tags including the newline character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the input file\n",
    "raw_data = open('Group163.txt','r').read()\n",
    "\n",
    "# creating a list, containing all records individually separated\n",
    "records = re.findall(r'<us-patent-grant(.*?)/us-patent-grant', str(raw_data),re.S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandoc\n",
      "  Downloading https://files.pythonhosted.org/packages/49/b1/d2d4b30ee81ea5cb7aee5ba3591752a637fdc49d0a42fa9683874b60b9fb/pandoc-1.0.2.tar.gz (488kB)\n",
      "Collecting ply (from pandoc)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n",
      "Installing collected packages: ply, pandoc\n",
      "  Running setup.py install for pandoc: started\n",
      "    Running setup.py install for pandoc: finished with status 'done'\n",
      "Successfully installed pandoc-1.0.2 ply-3.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.1.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Method\n",
    "\n",
    "For each field mentioned previously, a for loop is used to search each record in the list of records and the required information is selected for extraction using an appropriate regular expression. Extracted information is then stored in a list specific for that field. \n",
    "\n",
    "More specific method is discussed for each field.\n",
    "\n",
    "Each regular expression was tested for accuracy and specificity of text extracted using the sample input and output files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grant_id\n",
    "\n",
    "Each record is identified using a unique grant id. The location of grant id in the input file was found by searching for specific grant ids from the sample output. \n",
    "\n",
    "Regular expression used for this search is '\"(\\w*)-2'. This expression uniquely captures the grant id from the file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store grant id for each record.\n",
    "grant_id = []\n",
    "\n",
    "# for loop to iterate over all records to extract grant ids and append to the list.\n",
    "for record in records:\n",
    "    grant_id.append(\n",
    "        re.search(r'\"(\\w*)-2',record)\n",
    "        .group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### patent_kind\n",
    "\n",
    "Following approach was used to extract the patent kind information.\n",
    "\n",
    "Comparison of sample input and output showed that there is one to one relationship between a two digit code consisting of a letter and number between tags `<kind>` and `</kind>` in the input file and descriptive text in the sample output file. A dictionary linking these two digit codes with respective patent kind description was created. \n",
    "\n",
    "The patent kind code for each record was extracted using the regular expression: `>(\\w+)<\\/kind>(?!<name>)`\n",
    "This was then replaced with the patent kind description using the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store patent kind of each record.\n",
    "patent_kind = []\n",
    "\n",
    "# dictionary linking the two digit patent kind code and the descriptive text required for output.\n",
    "kind_dict = {\"B1\":\"Utility Patent Grant (no published application) issued on or after January 2, 2001.\", \"B2\":\"Utility Patent Grant (with a published application) issued on or after January 2, 2001.\",\"S1\":\"Design Patent\",\"E1\":\"Reissue Patent\",\"P2\":\"Plant Patent Grant (no published application) issued on or after January 2, 2001\",\"P3\":\"Plant Patent Grant (with a published application) issued on or after January 2, 2001\"}\n",
    "\n",
    "# extracting code for patent kind for each record and replacing it with the descriptive text using the dictionay.\n",
    "for record in records:\n",
    "    kind = re.search(r'>(\\w+)</kind>(?!<name>)', record).group(1)\n",
    "    for key in kind_dict.keys():\n",
    "        kind = kind.replace(key,kind_dict[key])\n",
    "    patent_kind.append(kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### patent_title\n",
    "\n",
    "Patent title was conveniently stored between tags `<invention-title....>` and `</invention-title>`. \n",
    "\n",
    "Regular expression '>(.*?)</invention-title>' was used for extracting patent title from each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store patent title for each record.\n",
    "patent_title = []\n",
    "\n",
    "# for loop to extract patent title from each record and append to the list.\n",
    "for record in records:\n",
    "    patent_title.append(\n",
    "        re.search(r'>(.*?)</invention-title>', record)\n",
    "        .group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no_of_claims\n",
    "\n",
    "No of claims was also conveniently stored between tags `<number-of-claims>` and `</number-of-claims>`. \n",
    "\n",
    "Regular expression `<number-of-claims>(.*?)</number-of-claims>` was used for extracting no of claims from each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store no of claims for each record.\n",
    "no_of_claims = []\n",
    "\n",
    "# for loop to extract no of claims from each record and append to the list.\n",
    "for record in records:\n",
    "    no_of_claims.append(re.search(r'<number-of-claims>(.*?)</number-of-claims>', record).group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inventor_name\n",
    "\n",
    "A record can contain one to many inventor names. Inventor names are also stored separately as first and last names within tags `<first-name>...</first-name>` and `<last-name>...</last-name>` respectively for each inventor, whose information is stored within tags `<inventor...>...</inventor>`.\n",
    "\n",
    "Last names for all inventors for a record were extracted as a list of strings using the findall function and the regular expression `<inventor.*?<last-name>(.*?)</last-name>`. First names were also extracted in a similar way. \n",
    "\n",
    "Two list of lists containing last names and first names of inventors for each record were created. \n",
    "\n",
    "The first and last name of each inventor was concatenated by iterating over each name within list of names within list for all records. \n",
    "\n",
    "In order to transform this into the format given in sample output, inventor names for each record were stored in a string with square brackets containing all inventor names for that record separated by a comma. .join() function and string formatting were used to achieve this.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store lists that contain first names of all inventors for each record.\n",
    "inventor_first_name = []\n",
    "\n",
    "# list to store lists that contain last names of all inventors for each record.\n",
    "inventor_last_name = []\n",
    "\n",
    "# list to store lists that contain full names of all inventors for each record obtained by concatenating\n",
    "# first and last names from the lists above. \n",
    "full_name = []\n",
    "\n",
    "# list to store lists that contains full names of all inventors in the format required for output.\n",
    "inventor_name = []\n",
    "\n",
    "# for loop to extract list of first names and last names from each record and append to the respective list.\n",
    "for record in records:\n",
    "    inventor_last_name.append(re.findall(r'<inventor.*?<last-name>(.*?)</last-name>', record, re.S))\n",
    "\n",
    "    inventor_first_name.append(re.findall(r'<inventor.*?<first-name>(.*?)</first-name>', record, re.S))\n",
    "\n",
    "# concatenating first and last names\n",
    "for i in range(len(inventor_first_name)):\n",
    "    full_name.append([])\n",
    "    for j in range(len(inventor_first_name[i])):\n",
    "        full_name[i].append((inventor_first_name[i][j]) + ' ' + (inventor_last_name[i][j]))\n",
    "\n",
    "# transforming list contents into the format required for output\n",
    "for name in full_name:\n",
    "    inventor_name.append(\"[%s]\" % (','.join(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### citations_applicant_count & citations_examiner_count\n",
    "\n",
    "It is specified for each citation in a record whether the citation is by the applicant or examiner. \n",
    "In order to obtain the number of citations by applicant, all instances of 'cited by applicant' are extracted in a list for each record and stored as the length of that list within the citations_applicant_count list. Similar method is used for citations by examiners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store the number of citations cited by the applicant\n",
    "citations_applicant_count = []\n",
    "\n",
    "# Using a for loop to extract all occurances of 'cited by applicant' for a record and storing the length of that list as count.\n",
    "for record in records:\n",
    "    citations_applicant_count.append(len(re.findall(r'cited by applicant', record)))\n",
    "    \n",
    "# list to store the number of citations cited by the examiner\n",
    "citations_examiner_count = []\n",
    "\n",
    "# Using a for loop to extract all occurances of 'cited by examiner' for a record and storing the length of that list as count.\n",
    "for record in records:\n",
    "    citations_examiner_count.append(len(re.findall(r'cited by examiner', record)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### abstract\n",
    "\n",
    "Abstract for each reacord is stored within tags `<abstract...>...</abstract>`. Within these tags multiple sub tags are used for identification of different parts of abstract, for example each paragraph of abstract is stored within `<p id...>...</p>`. A regular expression called internal tag is used to remove these sub tags but keep the abstract content within these tags. Another regular expression called new_line_tag is defined to remove all new line characters from within the abstract. \n",
    "These tags are removed by replacing them with an empty string using .sub() function. \n",
    "All abstract text is extracted from each record using the regular expression `<abstract.*?>(.*?)</abstract>`. When a record does not contain any abstract i.e searching of `<abstract.*?>(.*?)</abstract>` within a record yields `None`, 'NA' is appended to the list of abstracts. For the records containing abstract text, the text is cleaned up as described previously. This is then appended to the list of abstracts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store all abstract text for each record. \n",
    "abstract = []\n",
    "\n",
    "# Regular expression defined to remove all internal tags from within the abstract text.\n",
    "internal_tag = re.compile(r'<[^>]+>')\n",
    "\n",
    "# Regular expression defined to remove all new line characters from within the abstract text.\n",
    "new_line_tag = re.compile(r'[\\n]')\n",
    "\n",
    "# for loop to extract all abstract text for each record, append 'NA' if no abstract is given for a record and\n",
    "# append cleaned abstract text to list where abstract is given. \n",
    "\n",
    "for record in records:\n",
    "    raw_abstract = re.search(r'<abstract.*?>(.*?)</abstract>', record, re.S)\n",
    "    if raw_abstract == None :\n",
    "        abstract.append('NA')\n",
    "    else :\n",
    "        internal_tag_removed = internal_tag.sub('',raw_abstract.group(1))\n",
    "        new_line_tag_removed = new_line_tag.sub('',internal_tag_removed)\n",
    "        abstract.append(new_line_tag_removed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### claim_text\n",
    "\n",
    "Each record has multiple claims where each claim is recorded between tags `<claim id...>...</claim>`. Each claim has its own claim text, this however may be present as separate pieces of text, where each bit of claim text is enveloped between the tags `<claim-text>...</claim-text>` or `<claim-text>...\\n`.\n",
    "\n",
    "After extraction of claim text for all claims within a record using the regular expression `<claim id.*?>(.*?)</claim>`, we obtain a list of strings, where each string contains claim text for one of the claims within the record. From within each of these strings, claim text excluding all other information is extracted as list of strings using regular expression `<claim-text>(.*?)(?:</claim-text>)?[\\n]`. \n",
    "\n",
    "These list of strings are then joined together to form a string containing claim text for a claim. All strings of claim texts for all claims within a record are then joined together. The joins are performed using the .join() function. \n",
    "\n",
    "All internal tags are removed with a method similar to the one used for abstract. \n",
    "\n",
    "In order to transform this into the format given in sample output, claim text for each claim within each record were stored in a string with square brackets containing all claim text for all claims for that record separated by a comma. .join() function and string formatting were used to achieve this.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store claim text for all records. \n",
    "claim_text = []\n",
    "\n",
    "#for loop to extract claim text for each record and transform it into the format required for output\n",
    "for record in records:\n",
    "    \n",
    "    claim_text_raw = []\n",
    "    claim_text_concat = []\n",
    "    claim_text_records = []\n",
    "    \n",
    "    # extracting text for all claims within a record\n",
    "    claims_block = re.findall(r'<claim id.*?>(.*?)</claim>', record,re.S)\n",
    "    \n",
    "    # extracting only claim text from within each claim \n",
    "    for claim in claims_block:\n",
    "        claim_text_raw.append(re.findall(r\"<claim-text>(.*?)(?:</claim-text>)?[\\n]\", claim,re.S))\n",
    "    \n",
    "    # Joining together all text for a claim\n",
    "    i = 0\n",
    "    while i<len(claim_text_raw):\n",
    "        claim_text_concat.append(''.join(str(x) for x in claim_text_raw[i]))\n",
    "        i+=1\n",
    "        \n",
    "    # joining together all claims for a record, separated by a comma.    \n",
    "    claim_text_records.append(','.join(str(x) for x in claim_text_concat))\n",
    "    \n",
    "    # replacing internal tags with empty string\n",
    "    internal_tag_removed = internal_tag.sub('', claim_text_records[0])\n",
    "    \n",
    "    # replacing new line character with empty string\n",
    "    new_line_tag_removed = new_line_tag.sub('',internal_tag_removed)\n",
    "    \n",
    "    # transforming all claim text for a record to the required format and appending it to the list.\n",
    "    claim_text.append(\"[%s]\"%(new_line_tag_removed))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction and transformation complete\n",
    "\n",
    "At this stage, all required data is extracted into a field specific list in the required format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grant ID: ['USD0854286', 'US10357242', 'US10361198', 'US10359952'] \n",
      "\n",
      "\n",
      " Patent Title: ['Shoe', 'Suture delivery device', 'Integrated circuit devices and method of manufacturing the same', 'Method and system for implementing writable snapshots in a virtualized storage environment'] \n",
      "\n",
      "\n",
      " Kind: ['Design Patent', 'Utility Patent Grant (with a published application) issued on or after January 2, 2001.', 'Utility Patent Grant (with a published application) issued on or after January 2, 2001.', 'Utility Patent Grant (no published application) issued on or after January 2, 2001.'] \n",
      "\n",
      "\n",
      " No of claims: ['1', '8', '8', '21'] \n",
      "\n",
      "\n",
      " Inventor: ['[John Hlavacs]', '[Michi E. Garrison,Gregory M. Hyde,Richard J. Renati,Alan K. Schaer,Tony M. Chou]', '[Sidharth Rastogi,Subhash Kuchanuri,Raheel Azmat,Pan-jae Park,Chul-hong Park,Jae-seok Yang,Kwan-young Chun]', '[Mohit Aron,Brian Byrne]'] \n",
      "\n",
      "\n",
      " Citations Applicant Count: [10, 320, 11, 258] \n",
      "\n",
      "\n",
      " Citations Examiner Count: [34, 0, 0, 4] \n",
      "\n",
      "\n",
      " Claim Text: ['[The ornamental design for a shoe, as shown and described.]', '[1. A method of performing a procedure on a vascular or cardiac structure comprising:inserting a first sheath into the common carotid artery through an arteriotomy in the wall of the common carotid artery, wherein a suture delivery device is pre-mounted on the first sheath such that a distal region of the suture delivery device protrudes out of the distal end of the sheath to provide access to the blood vessel wall for the suture delivery device;inserting at least one therapeutic device through the sheath to a treatment site, performing a therapeutic procedure, and removing the at least one therapeutic device from the sheath;drawing at least one end of a suture outside the body of the patient using the suture delivery device such that the suture can be held until such time as the suture is to be tied off to create a permanent closure of the arteriotomy;removing the suture delivery device; andtying off the ends of the suture to close the arterial access site.,2. A method as in claim 1, further comprising the step of occluding the common carotid artery.,3. A method as in claim 2, wherein the first sheath includes a Y-arm connection to a flow line and further comprising the step of connecting the sheath to a reverse flow shunt.,4. A method as in claim 1, wherein the first sheath includes a detachable proximal extension tube, and further comprising the step of removing the proximal extension tube prior to inserting the suture delivery device.,5. A method as in claim 1, further comprising actuating a vessel wall locator for a first position which is generally in line with the elongate body to a second position which is generally extended away from said body.,6. A method as in claim 1, wherein the suture delivery device is formed of an elongate body having a movable arm, and further comprising:advancing a needle in a proximal to distal direction along at least a portion of the elongate body toward the arm, the needle being advanced through tissue of the common carotid artery;engaging a portion of the needle with the portion of the suture; andretracting the needle in a distal to proximal direction to draw the suture through the tissue.,7. A method as in claim 1, wherein the therapeutic device is a prosthetic aortic valve and the therapeutic procedure is transcatheter aortic valve implantation.,8. A method as in claim 1, wherein the suture delivery device is inserted into the common carotid artery through the arteriotomy in exchange for the sheath.]', '[1. An integrated circuit device, comprising:a substrate including a fin active region that extends in a first direction;a gate line intersecting the fin active region, the gate line extending in a second direction crossing the first direction and parallel to an upper surface of the substrate;a power line electrically connected to a source/drain region formed at a side of the gate line and on the fin active region;a pair of dummy gate lines intersecting the fin active region, the pair of dummy gate lines being spaced apart from the gate line and extending in the second direction; anda device separation structure electrically connected to the pair of dummy gate lines, the device separation structure including:a lower dummy contact plug formed between the pair of dummy gate lines and on the fin active region and electrically connected to the power line; andan upper dummy contact plug formed on the lower dummy contact plug and on the pair of dummy gate lines, the upper dummy contact plug electrically connecting the lower dummy contact plug to the pair of dummy gate lines.,2. The integrated circuit device as claimed in claim 1, wherein:the fin active region is a p-type metal-oxide-semiconductor (PMOS) transistor region and a drain voltage Vdd is applied to the device separation structure so that a pair of dummy transistors including the pair of dummy gate lines are turned off, orthe fin active region is an n-type metal-oxide-semiconductor (NMOS) transistor region and a source voltage Vss is applied to the device separation structure so that a pair of dummy transistors including the pair of dummy gate lines are turned off.,3. The integrated circuit device as claimed in claim 1, wherein an upper surface of the fin active region continuously extends from a lower portion of the pair of dummy gate lines to a lower portion of the gate line.,4. The integrated circuit device as claimed in claim 1, wherein the lower dummy contact plug vertically overlaps the upper dummy contact plug, and the lower dummy contact plug vertically overlaps a portion of the power line.,5. The integrated circuit device as claimed in claim 1, further comprising:an active contact plug on the source/drain region; anda gate contact plug on the gate line,wherein the active contact plug and the lower dummy contact plug include the same material, and the gate contact plug and the upper dummy contact plug include the same material.,6. The integrated circuit device as claimed in claim 1, wherein:the substrate includes a first fin active region that is a PMOS transistor region and a second fin active region that is an NMOS transistor region and is spaced apart from the first fin active region,the gate line extends in the second direction and intersects with both of the first fin active region and the second fin active region, andthe pair of dummy gate lines includes:a pair of first dummy gate lines extending in the second direction and intersecting the first fin active region; anda pair of second dummy gate lines spaced apart from the pair of first dummy gate lines, the pair of second dummy gate lines extending in the second direction and intersecting the second fin active region.,7. The integrated circuit device as claimed in claim 6, wherein:the substrate further includes a dummy region disposed between the first fin active region and the second fin active region,a dummy gate separation region between the pair of first dummy gate lines and the pair of second dummy gate lines is arranged on the dummy region, andthe device separation structure is configured to apply a drain voltage Vdd to the pair of first dummy gate lines and to apply a source voltage Vss to the pair of second dummy gate lines.,8. The integrated circuit device as claimed in claim 6, wherein each of the pair of first dummy gate lines and each of the pair of second dummy gate lines is placed on a straight line.]', '[1. A method comprising:identifying a parent snapshot of a virtual disk;creating a read snapshot of the parent snapshot, wherein the read snapshot is accessed in place of the parent snapshot without immediately copying all contents of the parent snapshot to the read snapshot;designating the read snapshot as a copy of the parent snapshot, wherein future data requests for the parent snapshot are directed to the read snapshot, the contents of the parent snapshot are copied to the read snapshot at a later time after creating the read snapshot;creating a writable snapshot of the parent snapshot, in which modifications are made to data items of the writable snapshot, wherein the writable snapshot can be accessed without immediately copying all of the contents of the parent snapshot to the writable snapshot, wherein an unchanged data item of the parent snapshot is copied to the writable snapshot at a later time after creating the writable snapshot; anddirecting future data write requests for the parent snapshot to the writable snapshot instead of the parent snapshot or the read snapshot, wherein a particular data item that is not in the writable snapshot is copied to the writable snapshot from the parent snapshot upon a request to modify the particular data item.,2. The method of claim 1, in which metadata is used to track referencing between the read snapshot or the writable snapshot and the parent snapshot of the virtual disk.,3. The method of claim 2, wherein the metadata comprises a first map corresponding to the virtual disk, a second map corresponding to extent identifiers, and a third map corresponding to groups of extents, and the read snapshot or the writable snapshot corresponds to entries within the metadata, wherein the virtual disk is exposed as a set of addressable storage units corresponding to a plurality of virtual disks structured from a global pool that comprises a local storage device on a first node and local storage device on a second node, the second node being different from the first node.,4. The method of claim 3 in which the writable snapshot corresponds to an extent group, and in which a first entry is made in the first map that corresponds to an identifier for the extent group to a virtual disk name for the writable snapshot, a second entry is made in the second map that corresponds to an extent group identifier for the extent group for the writable snapshot, and a third entry is made in the third map that corresponds to the extent group for the writable snapshot.,5. The method of claim 2, in which the metadata is copied to the writable snapshot from the parent snapshot instead of actual data.,6. The method of claim 1, in which a data item is copied from the parent snapshot to the read snapshot upon a need to access the data item in the read snapshot.,7. The method of claim 1, in which a first portion of the data item exists in the writable snapshot and a second portion of the data item is referenced to the parent snapshot.,8. A system comprising:a processor to handle computing instructions; anda computer readable medium comprising executable code that is executable by the processor for identifying a parent snapshot of a virtual disk; creating a read snapshot of the parent snapshot, wherein the read snapshot is accessed in place of the parent snapshot without immediately copying all contents of the parent snapshot to the read snapshot; designating the read snapshot as a copy of the parent snapshot, wherein future data requests for the parent snapshot are directed to the read snapshot, the contents of the parent snapshot are copied to the read snapshot at a later time after creating the read snapshot; creating a writable snapshot of the parent snapshot, in which modifications are made to data items of the writable snapshot, wherein the writable snapshot can be accessed without immediately copying all of the contents of the parent snapshot to the writable snapshot, wherein an unchanged data item of the parent snapshot is copied to the writable snapshot at a later time after creating the writable snapshot and directing future data write requests for the parent snapshot to the writable snapshot instead of the parent snapshot or the read snapshot, wherein a particular data item that is not in the writable snapshot is copied to the writable snapshot from the parent snapshot upon a request to modify the particular data item.,9. The system of claim 8, in which metadata is used to track referencing between the read snapshot or the writable snapshot and the parent snapshot of the virtual disk.,10. The system of claim 9, wherein the metadata comprises a first map corresponding to the virtual disk, a second map corresponding to extent identifiers, and a third map corresponding to groups of extents, and the read snapshot or the writable snapshot corresponds to entries within the metadata, wherein the virtual disk is exposed as a set of addressable storage units corresponding to a plurality of virtual disks structured from a global pool that comprises a local storage device on a first node and local storage device on a second node, the second node being different from the first node.,11. The system of claim 10, in which the writable snapshot corresponds to an extent group, and in which a first entry is made in the first map that corresponds to an identifier for the extent group to a virtual disk name for the writable snapshot, a second entry is made in the second map that corresponds to an extent group identifier for the extent group for the writable snapshot, and a third entry is made in the third map that corresponds to the extent group for the writable snapshot.,12. The system of claim 9, in which the metadata is copied to the writable snapshot from the parent snapshot instead of actual data.,13. The system of claim 8, in which a data item is copied from the parent snapshot to the read snapshot upon a need to access the data item in the read snapshot.,14. The system of claim 8, in which a first portion of the data item exists in the writable snapshot and a second portion of the data item is referenced to the parent snapshot.,15. A computer program product embodied on a computer usable medium, the computer usable medium having stored thereon a sequence of instructions which, when executed by a processor causes the processor to execute a method, the method comprising:identifying a parent snapshot of a virtual disk;creating a read snapshot of the parent snapshot, wherein the read snapshot is accessed in place of the parent snapshot without immediately copying all contents of the parent snapshot to the read snapshot;designating the read snapshot as a copy of the parent snapshot, wherein future data requests for the parent snapshot are directed to the read snapshot, the contents of the parent snapshot are copied to the read snapshot at a later time after creating the read snapshot;creating a writable snapshot of the parent snapshot, in which modifications are made to data items of the writable snapshot, wherein the writable snapshot can be accessed without immediately copying all of the contents of the parent snapshot to the writable snapshot, wherein an unchanged data item of the parent snapshot is copied to the writable snapshot at a later time after creating the writable snapshot; anddirecting future data write requests for the parent snapshot to the writable snapshot instead of the parent snapshot or the read snapshot, wherein a particular data item that is not in the writable snapshot is copied to the writable snapshot from the parent snapshot upon a request to modify the particular data item.,16. The computer program product of claim 15, in which metadata is used to track referencing between the read snapshot or the writable snapshot and the parent snapshot of the virtual disk.,17. The computer program product of claim 16, wherein the metadata comprises a first map corresponding to the virtual disk, a second map corresponding to extent identifiers, and a third map corresponding to groups of extents, and the read snapshot or the writable snapshot corresponds to entries within the metadata, wherein the virtual disk is exposed as a set of addressable storage units corresponding to a plurality of virtual disks structured from a global pool that comprises a local storage device on a first node and local storage device on a second node, the second node being different from the first node.,18. The computer program product of claim 17, in which the writable snapshot corresponds to an extent group, and in which a first entry is made in the first map that corresponds to an identifier for the extent group to a virtual disk name for the writable snapshot, a second entry is made in the second map that corresponds to an extent group identifier for the extent group for the writable snapshot, and a third entry is made in the third map that corresponds to the extent group for the writable snapshot.,19. The computer program product of claim 16, in which the metadata is copied to the writable snapshot from the parent snapshot instead of actual data.,20. The computer program product of claim 15, in which a data item is copied from the parent snapshot to the read snapshot upon a need to access the data item in the read snapshot.,21. The computer program product of claim 15, in which a first portion of the data item exists in the writable snapshot and a second portion of the data item is referenced to the parent snapshot.]'] \n",
      "\n",
      "\n",
      " Abstract: ['NA', 'A suture-based vessel closure device can perform the dilation of an arteriotomy puncture and does not require previous dilation of the arteriotomy puncture by a separate device or by a procedural sheath dilator. The suture-based vessel closure device can place one or more sutures across the vessel access site such that, when the suture ends are tied off after sheath removal, the stitch or stitches provide hemostasis to the access site.', 'An integrated circuit device includes a substrate including a fin active region extending in a first direction, a gate line intersecting the fin active region and extending in a second direction perpendicular to the first direction, a power line electrically connected to source/drain regions at sides of the gate line on the fin active region, a pair of dummy gate lines intersecting the fin active region and extending in the second direction, and a device separation structure electrically connected to the pair of dummy gate lines and including a lower dummy contact plug between the pair of dummy gate lines on the fin active region and electrically connected to the power line, and an upper dummy contact plug on the lower dummy contact plug and on the pair of dummy gate lines to electrically connect the lower dummy contact plug to the pair of dummy gate lines.', 'Disclosed is an improved approach for implementing and maintaining writable snapshots. An efficient approach is provided for implementing snapshots that can be used to immediately create snapshots without incurring any detectable delays in providing access to the new snapshots. Also described are improved metadata structures that can be used to implement and maintain the writable snapshots.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Grant ID:\", grant_id[:4], '\\n\\n\\n', \"Patent Title:\", patent_title[:4], '\\n\\n\\n', \"Kind:\", patent_kind[:4], \n",
    "      '\\n\\n\\n', \"No of claims:\", no_of_claims[:4] , '\\n\\n\\n', \"Inventor:\", inventor_name[:4], \n",
    "      '\\n\\n\\n', \"Citations Applicant Count:\", citations_applicant_count[:4], \n",
    "      '\\n\\n\\n', \"Citations Examiner Count:\", citations_examiner_count[:4], '\\n\\n\\n', \"Claim Text:\", claim_text[:4],\n",
    "     '\\n\\n\\n', \"Abstract:\", abstract[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export CSV file\n",
    "\n",
    "Pandas is used to create a dataframe using all lists created from the previous section. \n",
    "\n",
    "Pandas has a convenient method .to_csv() to write a dataframe to a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     grant_id                                       patent_title  \\\n",
      "0  USD0854286                                               Shoe   \n",
      "1  US10357242                             Suture delivery device   \n",
      "2  US10361198  Integrated circuit devices and method of manuf...   \n",
      "3  US10359952  Method and system for implementing writable sn...   \n",
      "\n",
      "                                                kind number_of_claims  \\\n",
      "0                                      Design Patent                1   \n",
      "1  Utility Patent Grant (with a published applica...                8   \n",
      "2  Utility Patent Grant (with a published applica...                8   \n",
      "3  Utility Patent Grant (no published application...               21   \n",
      "\n",
      "                                           inventors  \\\n",
      "0                                     [John Hlavacs]   \n",
      "1  [Michi E. Garrison,Gregory M. Hyde,Richard J. ...   \n",
      "2  [Sidharth Rastogi,Subhash Kuchanuri,Raheel Azm...   \n",
      "3                           [Mohit Aron,Brian Byrne]   \n",
      "\n",
      "   citations_applicant_count  citations_examiner_count  \\\n",
      "0                         10                        34   \n",
      "1                        320                         0   \n",
      "2                         11                         0   \n",
      "3                        258                         4   \n",
      "\n",
      "                                         claims_text  \\\n",
      "0  [The ornamental design for a shoe, as shown an...   \n",
      "1  [1. A method of performing a procedure on a va...   \n",
      "2  [1. An integrated circuit device, comprising:a...   \n",
      "3  [1. A method comprising:identifying a parent s...   \n",
      "\n",
      "                                            abstract  \n",
      "0                                                 NA  \n",
      "1  A suture-based vessel closure device can perfo...  \n",
      "2  An integrated circuit device includes a substr...  \n",
      "3  Disclosed is an improved approach for implemen...  \n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe using pandas\n",
    "df = pd.DataFrame(data={'grant_id': grant_id,'patent_title': patent_title,'kind': patent_kind,'number_of_claims': no_of_claims,'inventors': inventor_name,'citations_applicant_count': citations_applicant_count,'citations_examiner_count': citations_examiner_count,'claims_text': claim_text,'abstract': abstract})\n",
    "print(df[0:4])\n",
    "\n",
    "# creating a csv file from the dataframe\n",
    "df.to_csv(\"Group163final.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export JSON file \n",
    "\n",
    "In order to complete this task, the sample output file in JSON version was checked for the JSON structure. JSON structure works as key-value pairs. In the output file, grant_id for each record was used as its key. The set of remaining fields for the record in a key-value structure with field title as the key and the record data as its value was recorded as the value for each grant_id. \n",
    "\n",
    "All field titles are stored in a list. \n",
    "\n",
    "1. All the key-value pairs of fields titles and its content (excluding Grant ID) for the record is stored within curly brackets as a string for each record within a list. \n",
    "\n",
    "2. All grant id and the respective string from step 1 are then stored as key value pairs as a string for each record in a list. \n",
    "\n",
    "3. All elements in the list list from step 2 are joined into one single string with each element separated by a comma using the .join() function and the entire string placed into a set of curly brackets. \n",
    "\n",
    "4. The string from step 3 is then written into a .json file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grant_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8b103428a6fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrant_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     key_value_level2.append('{\"'\n\u001b[0;32m     10\u001b[0m         \u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\":\"'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatent_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\",\"'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grant_id' is not defined"
     ]
    }
   ],
   "source": [
    "# list of all field titles\n",
    "headers = [\"patent_title\",\"kind\",\"number_of_claims\",\"inventors\",\"citations_applicant_count\",\"citations_examiner_count\",\"claims_text\",\"abstract\"]\n",
    "\n",
    "# list to store all key value pairs (except grant id) for all records\n",
    "key_value_level2 = []\n",
    "\n",
    "i = 0\n",
    "while i < len(grant_id):\n",
    "    key_value_level2.append('{\"'\n",
    "        +str(headers[0])+'\":\"'+str(patent_title[i])+'\",\"'\n",
    "        +str(headers[1])+'\":\"'+str(patent_kind[i])+'\",\"'\n",
    "        +str(headers[2])+'\":'+str(no_of_claims[i])+',\"'\n",
    "        +str(headers[3])+'\":\"'+str(inventor_name[i])+'\",\"'\n",
    "        +str(headers[4])+'\":'+str(citations_applicant_count[i])+',\"'\n",
    "        +str(headers[5])+'\":'+str(citations_examiner_count[i])+',\"'\n",
    "        +str(headers[6])+'\":\"'+str(claim_text[i])+'\",\"'\n",
    "        +str(headers[7])+'\":\"'+str(abstract[i])+'\"}')\n",
    "    i+=1\n",
    "\n",
    "# list to store all key value pairs of grant-id and its respective content from the list key_value_level2\n",
    "key_value_level1 = []\n",
    "\n",
    "j = 0  \n",
    "while j < len(grant_id):\n",
    "    key_value_level1.append('\"'+str(grant_id[j])+'\":'+str(key_value_level2[j]))\n",
    "    j+=1\n",
    "\n",
    "# Joining key value pairs of all records separated by a comma into a single string within curly brackets\n",
    "json_string = \"{\"+\",\".join(key_value_level1)+\"}\"\n",
    "\n",
    "#writing the json format string into a file\n",
    "f= open(\"Group163final.json\",\"w+\")\n",
    "f.write(str(json_string))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hex code\n",
    "\n",
    "Certain characters in the input file are encoded in the HTML hex code. It appears from reviewing the sample input and output files that the code written to create those files is able to handle the hex code and convert it to the respective character when viewed in a text editor. We managed to figure out a way to do this as described below. We have described here the approach we used to deal with the codes, however given that we were not required to handle these codes and at this stage had not solved all remaining codes, we decided to leave them as is. \n",
    "\n",
    "The solution we developed was to compile a regular expression for the hex code in the input file and then replace it with the python encoding for the unicode character. \n",
    "\n",
    "example: \n",
    "hex code - &#x2018\n",
    "python unicode - u\"\\u2018\"\n",
    "\n",
    "code_re = re.compile(r'&#x2018')\n",
    "transformed_string = code_re.sub(u\"\\u2018\",str'string to be converted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References\n",
    "\n",
    "- Biek M. (2008, September 4). *How would you make a comma-separated string from a list?* [Response to]. Retrieved from http://stackoverflow.com/a/44781\n",
    "\n",
    "- pandas: powerful Python data analysis toolkit. (2019). *pandas 0.25.1 documentation: pandas.DataFrame.to_csv*. Retrieved from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
    "\n",
    "- Python 3.7.4 documentation. (2019). *re — Regular expression operations* . Retrieved from https://docs.python.org/3/library/re.html#module-re\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
